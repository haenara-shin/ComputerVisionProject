{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"opencv_ssd_inference.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AWqDbzXReMkX"},"source":["### OpenCV DNN을 이용하여 SSD 기반 Object Detection 수행\n","* Tensorflow 에서 Pretrained 된 모델 파일을 OpenCV에서 로드하여 이미지와 영상에 대한 Object Detection 수행.\n","* SSD+Inception과 SSD+MobileNet v3 를 모두 테스트\n","* CPU기반 환경에서 SSD의 Inference 속도 주시. "]},{"cell_type":"markdown","metadata":{"id":"WrzQFh2heMka"},"source":["#### 입력 이미지로 사용될 이미지 다운로드\n"]},{"cell_type":"code","metadata":{"id":"CP7z351geMkc"},"source":["!mkdir /content/data\n","!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2uqlttIJeMkp"},"source":["#### Tensorflow에서 Pretrained 된 Inference모델(Frozen graph)와 환경파일을 다운로드 받은 후 이를 이용해 OpenCV에서 Inference 모델 생성\n","* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음.\n","* pretrained 모델은 http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz 에서 다운로드 후 압축 해제\n","* pretrained 모델을 위한 환경 파일은 https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_inception_v2_coco_2017_11_17.pbtxt 에서 다운로드 \n","* download된 모델 파일과 config 파일을 인자로 하여 inference 모델을 DNN에서 로딩함. \n"]},{"cell_type":"code","metadata":{"id":"fu8VV9p91LLw"},"source":["!mkdir ./pretrained\n","\n","!wget -O ./pretrained/ssd_inception_v2_coco_2017_11_17.tar.gz http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz \n","!wget -O ./pretrained/ssd_config_01.pbtxt  https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/ssd_inception_v2_coco_2017_11_17.pbtxt\n","\n","!tar -xvf ./pretrained/ssd_inception*.tar.gz -C ./pretrained "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hrNcBdWY1uoN"},"source":["!pwd\n","!ls -lia ./pretrained/ssd_inception*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3C6Gtw-v2GDk"},"source":["#### dnn에서 readNetFromTensorflow()로 tensorflow inference 모델을 로딩"]},{"cell_type":"code","metadata":{"id":"DQbnBcUdeMk5"},"source":["import cv2\n","\n","cv_net = cv2.dnn.readNetFromTensorflow('/content/pretrained/ssd_inception_v2_coco_2017_11_17/frozen_inference_graph.pb',\n","                                      '/content/pretrained/ssd_config_01.pbtxt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jbSAASzdeMlA"},"source":["#### coco 데이터 세트의 클래스id별 클래스명 지정. "]},{"cell_type":"code","metadata":{"id":"3spingJOtXJF"},"source":["labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n","                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n","                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n","                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n","                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n","                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n","                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n","                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n","                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n","                    91:'hair brush'}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U0BYbmG0eMlI"},"source":["#### 이미지를 preprocessing 수행하여 Network에 입력하고 Object Detection 수행 후 결과를 이미지에 시각화 "]},{"cell_type":"code","metadata":{"id":"GIOyisS3eMlK"},"source":["import matplotlib.pyplot as plt\n","import cv2\n","\n","img = cv2.imread('/content/data/beatles01.jpg')\n","\n","# 원본 이미지 (633, 806)를 네트웍에 입력시에는 (300, 300)로 resize 함. \n","# 이후 결과가 출력되면 resize된 이미지 기반으로 bounding box 위치가 예측 되므로 이를 다시 원복하기 위해 원본 이미지 shape정보 필요\n","rows = img.shape[0]\n","cols = img.shape[1]\n","# cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \n","draw_img = img.copy()\n","\n","# 원본 이미지 배열을 사이즈 (300, 300)으로, BGR을 RGB로 변환하여 배열 입력\n","cv_net.setInput(cv2.dnn.blobFromImage(img,  size=(300, 300), swapRB=True, crop=False))\n","# Object Detection 수행하여 결과를 cv_out으로 반환 \n","cv_out = cv_net.forward()\n","print(cv_out.shape)\n","\n","# bounding box의 테두리와 caption 글자색 지정\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","# detected 된 object들을 iteration 하면서 정보 추출\n","for detection in cv_out[0,0,:,:]:\n","    score = float(detection[2])\n","    class_id = int(detection[1])\n","    # detected된 object들의 score가 0.4 이상만 추출\n","    if score > 0.4:\n","        # detected된 object들은 image 크기가 (300, 300)으로 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n","        left = detection[3] * cols\n","        top = detection[4] * rows\n","        right = detection[5] * cols\n","        bottom = detection[6] * rows\n","        # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n","        caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n","        \n","        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n","        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n","        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, red_color, 2)\n","        print(caption, class_id)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KSoSkTexeMlP"},"source":["#### 단일 이미지의 object detection을 함수로 생성"]},{"cell_type":"code","metadata":{"id":"qk9sOZnteMlQ"},"source":["import time\n","\n","def get_detected_img(cv_net, img_array, score_threshold, is_print=True):\n","    \n","    rows = img_array.shape[0]\n","    cols = img_array.shape[1]\n","    \n","    draw_img = img_array.copy()\n","    \n","    cv_net.setInput(cv2.dnn.blobFromImage(img_array, size=(300, 300), swapRB=True, crop=False))\n","    \n","    start = time.time()\n","    cv_out = cv_net.forward()\n","    \n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","\n","    # detected 된 object들을 iteration 하면서 정보 추출\n","    for detection in cv_out[0,0,:,:]:\n","        score = float(detection[2])\n","        class_id = int(detection[1])\n","        # detected된 object들의 score가 0.4 이상만 추출\n","        if score > score_threshold:\n","            # detected된 object들은 image 크기가 (300, 300)으로 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n","            left = detection[3] * cols\n","            top = detection[4] * rows\n","            right = detection[5] * cols\n","            bottom = detection[6] * rows\n","            # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n","            caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n","\n","            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n","            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n","            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, red_color, 2)\n","    if is_print:\n","        print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n","\n","    return draw_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9yHawXneMlV"},"source":["# image 로드 \n","img = cv2.imread('/content/data/beatles01.jpg')\n","\n","#coco dataset 클래스명 매핑\n","\n","# Object Detetion 수행 후 시각화 \n","draw_img = get_detected_img(cv_net, img, score_threshold=0.4, is_print=True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVbhU-1ol-bO"},"source":["!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg\n","\n","img = cv2.imread('/content/data/baseball01.jpg')\n","\n","#coco dataset 클래스명 매핑\n","\n","# Object Detetion 수행 후 시각화 \n","draw_img = get_detected_img(cv_net, img, score_threshold=0.4, is_print=True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4dXqj8MeMla"},"source":["### Video Object Detection 수행"]},{"cell_type":"code","metadata":{"id":"6ItMwC_WeMld"},"source":["!wget -O ./data/Jonh_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxRe2zVGeMlj"},"source":["#### VideoCapture와 VideoWriter 설정하고 Video Detection용 전용 함수 생성\n","* VideoCapture를 이용하여 Video를 frame별로 capture 할 수 있도록 설정\n","* VideoCapture의 속성을 이용하여 Video Frame의 크기 및 FPS 설정. \n","* VideoWriter를 위한 인코딩 코덱 설정 및 영상 write를 위한 설정\n","총 Frame 별로 iteration 하면서 Object Detection 수행. 개별 frame별로 단일 이미지 Object Detection과 유사 "]},{"cell_type":"code","metadata":{"id":"EWQOFbS3eMll"},"source":["def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt, )\n","\n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        \n","        returned_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, is_print=True)\n","        vid_writer.write(returned_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASFbf8eGeMlr"},"source":["do_detected_video(cv_net, '/content/data/Jonh_Wick_small.mp4', './data/John_Wick_small_incept.mp4', 0.2, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUC5ExKBeMl1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pe73Mt-IeMl8"},"source":["### SSD+Mobilenet v3 Object Detection 수행. \n","* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음. \n","* weight파일은 http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz 에서 다운로드\n","* SSD + Mobilenet v3 backbone은 opencv dnn 모듈이 아니라 dnn_DetectionModel() 함수로 생성 가능하며, 이를 사용하기 위해서는 Opencv의 버전을 Upgrade해야함. "]},{"cell_type":"code","metadata":{"id":"q54TjunD40Il"},"source":["!mkdir ./pretrained\n","!wget -O ./pretrained/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz\n","!wget -O ./pretrained/ssd_config_02.pbtxt https://gist.githubusercontent.com/dkurt/54a8e8b51beb3bd3f770b79e56927bd7/raw/2a20064a9d33b893dd95d2567da126d0ecd03e85/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\n","\n","!!tar -xvf ./pretrained/ssd_mobilenet*.tar.gz -C ./pretrained "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2WaUaiM6sfJ"},"source":["print(cv2.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oROmSOsKgMQI"},"source":["### opencv의 버전을 Upgrade한 후 dnn_DetectionModel() 사용.\n","* https://github.com/opencv/opencv/pull/16760 \n","* dnn_DetectionModel()은 dnn_Model 객체 반환\n","* 해당 SSD 모델은 image pixel값을 -1 ~ 1 사이로 정규화하고 image size는 320, 320으로 설정.\n"]},{"cell_type":"code","metadata":{"id":"3s2sRyw45xOy"},"source":["!pip install opencv-python==4.5.2.54"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NnCRqxpq60sh"},"source":["import cv2\n","\n","cv_net_m = cv2.dnn_DetectionModel('/content/pretrained/ssd_mobilenet_v3_large_coco_2020_01_14/frozen_inference_graph.pb',\n","                                      '/content/pretrained/ssd_config_02.pbtxt')\n","cv_net_m.setInputSize(320, 320)\n","cv_net_m.setInputScale(1.0 / 127.5)\n","cv_net_m.setInputMean((127.5, 127.5, 127.5))\n","cv_net_m.setInputSwapRB(True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-5rBoplnjdo2"},"source":["### dnn_Model 객체의 detect() 메소드는 입력 이미지를 받아서 특정 confidence threshold 이상의 모든 object inference 결과를 반환. \n","* class id값, confidence score값, bbox 좌표값이 arrary로 반환됨.\n","* bbox 좌표값의 경우 0~1사이 값이 아니라 정수형의 위치값이 반환됨. 단 xmin, ymin, width, height 형태로 반환되므로 유의 필요. "]},{"cell_type":"code","metadata":{"id":"99q1mZKB7I8u"},"source":["img = cv2.imread('/content/data/beatles01.jpg')\n","draw_img = img.copy()\n","\n","classes, confidences, boxes = cv_net_m.detect(img, confThreshold=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpUuSqC-7Lv6"},"source":["classes, confidences, boxes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDhtxZKpwctv"},"source":["classes.shape, confidences.shape, boxes.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cp5wUqcOk6QL"},"source":["labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n","                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n","                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n","                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n","                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n","                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n","                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n","                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n","                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n","                    91:'hair brush'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZCWo0fe7ObC"},"source":["import matplotlib.pyplot as plt\n","\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","for class_id, confidence_score, box in zip(classes.flatten(), confidences.flatten(), boxes):\n","    if confidence_score > 0.5:\n","      caption = \"{}: {:.4f}\".format(labels_to_names[class_id], confidence_score)\n","      # box 반환 좌표값은 정수형 위치 좌표임. xmin, ymin, width, height임에 유의 \n","      cv2.rectangle(draw_img, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), color=green_color, thickness=2)\n","      cv2.putText(draw_img, caption, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, red_color, 2)\n","      print(caption, class_id, box)  \n","\n","draw_img = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(draw_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WuIOcDu1k-1i"},"source":["#### 단일 이미지의 object detection을 함수로 생성"]},{"cell_type":"code","metadata":{"id":"hNvGnp5pSX4q"},"source":["import time \n","def get_detected_img_renew(cv_net, img_array, score_threshold, is_print=True):\n","    \n","  draw_img = img_array.copy()\n","   \n","  start = time.time()\n","\n","  classes, confidences, boxes = cv_net.detect(img_array, confThreshold=0.5)\n","  \n","  green_color=(0, 255, 0)\n","  red_color=(0, 0, 255)\n","\n","  # detected 된 object들을 iteration 하면서 정보 추출\n","  for class_id, confidence_score, box in zip(classes.flatten(), confidences.flatten(), boxes):\n","    if confidence_score > 0.5:\n","      caption = \"{}: {:.4f}\".format(labels_to_names[class_id], confidence_score)\n","      cv2.rectangle(draw_img, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), color=green_color, thickness=2)\n","      cv2.putText(draw_img, caption, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, red_color, 2)\n","      print(caption)\n","  \n","  if is_print:\n","      print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n","\n","  return draw_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NRItwDJkrdA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pfIWJ-DyUHlH"},"source":["## dnn_Model을 만드는 함수 생성. \n","def get_cv_detection_model(pretrained_path, config_path):\n","  cv_net = cv2.dnn_DetectionModel(pretrained_path, config_path)\n","  cv_net.setInputSize(320, 320)\n","  cv_net.setInputScale(1.0 / 127.5)\n","  cv_net.setInputMean((127.5, 127.5, 127.5))\n","  cv_net.setInputSwapRB(True)\n","\n","  return cv_net\n","\n","cv_net_m = get_cv_detection_model('/content/pretrained/ssd_mobilenet_v3_large_coco_2020_01_14/frozen_inference_graph.pb',\n","                       '/content/pretrained/ssd_config_02.pbtxt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luJDB3RxUV7P"},"source":["img = cv2.imread('./data/beatles01.jpg')\n","\n","# Object Detetion 수행 후 시각화 \n","draw_img = get_detected_img_renew(cv_net_m, img, score_threshold=0.5,  is_print=True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"krsSCI33lwFR"},"source":["!wget -O ./data/baseball01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/baseball01.jpg\n","\n","img = cv2.imread('./data/baseball01.jpg')\n","\n","# Object Detetion 수행 후 시각화 \n","draw_img = get_detected_img_renew(cv_net_m, img, score_threshold=0.5,  is_print=True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Eulfo4tmSu-"},"source":["### Video Inferece 수행."]},{"cell_type":"code","metadata":{"id":"ORMFN4TYmYoO"},"source":["!wget -O ./data/Jonh_Wick_small.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/John_Wick_small.mp4?raw=true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zdJAMIEKU-T3"},"source":["def do_detected_video_renew(cv_net, input_path, output_path, score_threshold, is_print):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt, )\n","\n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        \n","        returned_frame = get_detected_img_renew(cv_net, img_frame, score_threshold=score_threshold, is_print=True)\n","        vid_writer.write(returned_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IG-L2h8VCMl"},"source":["do_detected_video_renew(cv_net_m, '/content/data/Jonh_Wick_small.mp4', './data/John_Wick_small_m3.mp4', 0.2, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ztd0lsr2F8L"},"source":[""],"execution_count":null,"outputs":[]}]}
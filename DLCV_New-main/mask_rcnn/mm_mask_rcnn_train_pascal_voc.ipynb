{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mm_mask_rcnn_train_pascal_voc.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrhTHrMVVIf0FzryB26URd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"c7XRP9bwSfJu"},"source":["### MMDetection 설치"]},{"cell_type":"code","metadata":{"id":"xJkO1dPo1-2b"},"source":["!pip install mmcv-full\n","!git clone https://github.com/open-mmlab/mmdetection.git\n","!cd mmdetection; python setup.py install"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbAnpNg9Q8dG"},"source":["# 런타임->런타임 다시 시작 후 아래 수행. \n","from mmdet.apis import init_detector, inference_detector\n","import mmcv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tjsrX8SFSnK7"},"source":["### PASCAL VOC 2007 데이터 세트 다운로드"]},{"cell_type":"code","metadata":{"id":"rKHMaXju2EOE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623899395941,"user_tz":-540,"elapsed":23623,"user":{"displayName":"권철민","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03917677622451543916"}},"outputId":"8f39b2a6-0ae8-4884-e3d2-33c1e3c7ff01"},"source":["!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n","!tar -xvf VOCtrainval_06-Nov-2007.tar > /dev/null 2>&1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-06-17 03:09:32--  http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar [following]\n","--2021-06-17 03:09:32--  https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 460032000 (439M) [application/octet-stream]\n","Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n","\n","VOCtrainval_06-Nov- 100%[===================>] 438.72M  21.7MB/s    in 20s     \n","\n","2021-06-17 03:09:53 (21.6 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-rvSmtd4SyIW"},"source":["### MMDetection은 Mask RCNN을 학습하기 위해서는 COCO 포맷을 가장 선호\n","* CocoDataset으로 지정해야만, evaluation 시 mask evaluation 정보 제공.(2021년 6월 기준) https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html\n","* Pascal voc 포맷을 Coco 포맷으로 변환할 수 있는 유틸리티를 활용하여 데이터 변환\n","https://github.com/ISSResearch/Dataset-Converters\n","* Dataset converter 패키지가 opencv를 3.4로 downgrade함에 유의"]},{"cell_type":"code","metadata":{"id":"KJg7Mj7rYIlG"},"source":["import cv2\n","print(cv2.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KQXbBV7wBjO"},"source":["!git clone https://github.com/ISSResearch/Dataset-Converters.git\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rk8lq3PNjsig"},"source":["!cd Dataset-Converters; pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aDFbNkjWQmh"},"source":["!mkdir /content/coco_output\n","!cd Dataset-Converters;python convert.py --input-folder /content/VOCdevkit/VOC2007 --output-folder /content/coco_output \\\n","                  --input-format VOCSEGM --output-format COCO --copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7xdA8F_ZT3E"},"source":["!pip install opencv-python==4.1.2.30"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wh0LZFGwbB_5"},"source":["### 생성된 Coco Annotation json 파일 살펴 보기"]},{"cell_type":"code","metadata":{"id":"TROJ8YQuaOTp"},"source":["!sudo apt-get install jq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uX7X1MoSaOXM"},"source":["!jq . /content/coco_output/annotations/train.json > output.json "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OhzkICHXaOaa"},"source":["!head -200 output.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jg1nUKl6aOdC"},"source":["!tail -200 output.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_zTNFwsSakv6"},"source":["!grep -n 'annotations' output.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8hp4Ufz7apHW"},"source":["!head -1600 output.json | tail -400 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dBldbcCSbUj3"},"source":["### Pretrained 모델 다운로드 및 Config, Dataset설정."]},{"cell_type":"code","metadata":{"id":"0bEeppPQG_sr"},"source":["# pretrained weight 모델을 다운로드 받기 위해서 mmdetection/checkpoints 디렉토리를 만듬. \n","!cd mmdetection; mkdir checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwcBRmjdQDLQ"},"source":["!wget -O /content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_fpn_1x_coco/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ifz2eS2lBqMJ"},"source":["!ls -lia /content/mmdetection/checkpoints"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3uTqmO5EQDOC"},"source":["# config 파일을 설정하고, 다운로드 받은 pretrained 모델을 checkpoint로 설정. \n","config_file = '/content/mmdetection/configs/mask_rcnn/mask_rcnn_r101_fpn_1x_coco.py'\n","checkpoint_file = '/content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WKPZrx6HQDQe"},"source":["from mmdet.datasets.builder import DATASETS\n","from mmdet.datasets.coco import CocoDataset\n","\n","@DATASETS.register_module(force=True)\n","class VOCDataset(CocoDataset):\n","  CLASSES = ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n","               'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n","               'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',\n","               'tvmonitor')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrPweafhQDTd"},"source":["from mmcv import Config\n","\n","cfg = Config.fromfile(config_file)\n","print(cfg.pretty_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"udEntY3Gj8VP"},"source":["from mmdet.apis import set_random_seed\n","\n","# dataset에 대한 환경 파라미터 수정. \n","cfg.dataset_type = 'VOCDataset'\n","cfg.data_root = '/content/coco_output/'\n","\n","# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \n","cfg.data.train.type = 'VOCDataset'\n","cfg.data.train.data_root = '/content/coco_output/'\n","cfg.data.train.ann_file = 'annotations/train.json'\n","cfg.data.train.img_prefix = 'train'\n","\n","cfg.data.val.type = 'VOCDataset'\n","cfg.data.val.data_root = '/content/coco_output/'\n","cfg.data.val.ann_file = 'annotations/val.json'\n","cfg.data.val.img_prefix = 'val'\n","\n","\n","# class의 갯수를 pascal voc로 설정.  수정. \n","cfg.model.roi_head.bbox_head.num_classes = 20\n","cfg.model.roi_head.mask_head.num_classes = 20\n","\n","# pretrained 모델\n","cfg.load_from = '/content/mmdetection/checkpoints/mask_rcnn_r101_fpn_1x_coco_20200204-1efe0ed5.pth'\n","\n","# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \n","cfg.work_dir = './tutorial_exps'\n","\n","# 학습율 변경 환경 파라미터 설정. \n","cfg.optimizer.lr = 0.02 / 8\n","cfg.lr_config.warmup = None\n","cfg.log_config.interval = 10\n","\n","# CocoDataset의 경우 metric을 bbox로 설정해야 함.(mAP아님. bbox로 설정하면 mAP를 iou threshold를 0.5 ~ 0.95까지 변경하면서 측정)\n","cfg.evaluation.metric = ['bbox', 'segm']\n","cfg.evaluation.interval = 12\n","cfg.checkpoint_config.interval = 12\n","\n","# 두번 config를 로드하면 lr_config의 policy가 사라지는 오류로 인하여 설정. \n","cfg.lr_config.policy='step'\n","# Set seed thus the results are more reproducible\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXbuUXRyj8Yt"},"source":["print(cfg.pretty_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wd2Bik8Fj8cD"},"source":["from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector\n","\n","# train용 Dataset 생성. \n","datasets = [build_dataset(cfg.data.train)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7YF5h7Hj8ft"},"source":["model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n","model.CLASSES = datasets[0].CLASSES\n","print(model.CLASSES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgxxeD9Jj8ia"},"source":["import os.path as osp\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","# epochs는 config의 runner 파라미터로 지정됨. 기본 12회 \n","train_detector(model, datasets, cfg, distributed=False, validate=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEm1hGrzdV0o"},"source":["### 학습된 모델을 이용하여 단일 이미지와 Video Inference 수행. "]},{"cell_type":"code","metadata":{"id":"IS78SaUh5giE"},"source":["from mmdet.apis import show_result_pyplot\n","\n","checkpoint_file = '/content/tutorial_exps/epoch_12.pth'\n","\n","# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \n","model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')\n","# BGR Image 사용 \n","img = cv2.imread('/content/VOCdevkit/VOC2007/JPEGImages/000007.jpg')\n","#model_ckpt.cfg = cfg\n","\n","result = inference_detector(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, score_thr=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zQONtMS6bRn"},"source":["!mkdir /content/data\n","!wget -O ./data/beatles01.jpg https://raw.githubusercontent.com/chulminkw/DLCV/master/data/image/beatles01.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEAdcLjA6bgt"},"source":["img = cv2.imread('/content/data/beatles01.jpg')\n","#model_ckpt.cfg = cfg\n","\n","result = inference_detector(model_ckpt, img)\n","show_result_pyplot(model_ckpt, img, result, score_thr=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcX5PLi37cy2"},"source":["### Video Inference 수행\n","* get_detected_img()함수를 이용하여 Inference 수행. "]},{"cell_type":"code","metadata":{"id":"4UKrr1Hfj8nx"},"source":["!wget -O /content/data/London_Street.mp4 https://github.com/chulminkw/DLCV/blob/master/data/video/London_Street.mp4?raw=true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuOty1BK7da2"},"source":["import numpy as np\n","\n","labels_to_names_seq =  {0:'aeroplane', 1:'bicycle', 2:'bird', 3:'boat', 4:'bottle', 5:'bus', 6:'car',\n","               7:'cat', 8:'chair', 9:'cow', 10:'diningtable', 11:'dog', 12:'horse',\n","               13:'motorbike', 14:'person', 15:'pottedplant', 16:'sheep', 17:'sofa', 18:'train',\n","               19:'tvmonitor'}\n","  \n","colors = list(\n","    [[0, 255, 0],\n","     [0, 0, 255],\n","     [255, 0, 0],\n","     [0, 255, 255],\n","     [255, 255, 0],\n","     [255, 0, 255],\n","     [80, 70, 180],\n","     [250, 80, 190],\n","     [245, 145, 50],\n","     [70, 150, 250]] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgNcOvwm7QbQ"},"source":["# model과 원본 이미지 array, filtering할 기준 class confidence score를 인자로 가지는 inference 시각화용 함수 생성. \n","# 이미 inference 시 mask boolean값이 들어오므로 mask_threshold 값을 필요하지 않음. \n","def get_detected_img(model, img_array,  score_threshold=0.3, is_print=True):\n","  # 인자로 들어온 image_array를 복사. \n","  draw_img = img_array.copy()\n","  bbox_color=(0, 255, 0)\n","  text_color=(0, 0, 255)\n","\n","  # model과 image array를 입력 인자로 inference detection 수행하고 결과를 results로 받음. \n","  # results는 80개의 2차원 array(shape=(오브젝트갯수, 5))를 가지는 list. \n","  results = inference_detector(model, img_array)\n","  bbox_results = results[0]\n","  seg_results = results[1]\n","\n","  # 80개의 array원소를 가지는 results 리스트를 loop를 돌면서 개별 2차원 array들을 추출하고 이를 기반으로 이미지 시각화 \n","  # results 리스트의 위치 index가 바로 COCO 매핑된 Class id. 여기서는 result_ind가 class id\n","  # 개별 2차원 array에 오브젝트별 좌표와 class confidence score 값을 가짐. \n","  for result_ind, bbox_result in enumerate(bbox_results):\n","    # 개별 2차원 array의 row size가 0 이면 해당 Class id로 값이 없으므로 다음 loop로 진행. \n","    if len(bbox_result) == 0:\n","      continue\n","    \n","    mask_array_list = seg_results[result_ind]\n","    \n","    # 해당 클래스 별로 Detect된 여러개의 오브젝트 정보가 2차원 array에 담겨 있으며, 이 2차원 array를 row수만큼 iteration해서 개별 오브젝트의 좌표값 추출. \n","    for i in range(len(bbox_result)):\n","      # 좌상단, 우하단 좌표 추출. \n","      if bbox_result[i, 4] > score_threshold:\n","        left = int(bbox_result[i, 0])\n","        top = int(bbox_result[i, 1])\n","        right = int(bbox_result[i, 2])\n","        bottom = int(bbox_result[i, 3])\n","        caption = \"{}: {:.4f}\".format(labels_to_names_seq[result_ind], bbox_result[i, 4])\n","        cv2.rectangle(draw_img, (left, top), (right, bottom), color=bbox_color, thickness=2)\n","        cv2.putText(draw_img, caption, (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 0.37, text_color, 1)\n","        # masking 시각화 적용. class_mask_array는 image 크기 shape의  True/False값을 가지는 2차원 array\n","        class_mask_array = mask_array_list[i]\n","        # 원본 image array에서 mask가 True인 영역만 별도 추출. \n","        masked_roi = draw_img[class_mask_array]\n","        #color를 임의 지정\n","        #color_index = np.random.randint(0, len(colors)-1)\n","        # color를 class별로 지정\n","        color_index = result_ind % len(colors)\n","        color = colors[color_index]\n","        # apply_mask()함수를 적용시 수행 시간이 상대적으로 오래 걸림. \n","        #draw_img = apply_mask(draw_img, class_mask_array, color, alpha=0.4)\n","        # 원본 이미지의 masking 될 영역에 mask를 특정 투명 컬러로 적용\n","        draw_img[class_mask_array] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.6 * masked_roi).astype(np.uint8)\n","        if is_print:\n","          print(caption)\n","  \n","  return draw_img\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOnTeurI78Ny"},"source":["import time\n","\n","def do_detected_video(model, input_path, output_path, score_threshold, do_print=True):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt)\n","    btime = time.time()\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        stime = time.time()\n","        img_frame = get_detected_img(model, img_frame,  score_threshold=score_threshold,is_print=False)\n","        if do_print:\n","          print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n","        vid_writer.write(img_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()\n","\n","    print('최종 detection 완료 수행 시간:', round(time.time() - btime, 4))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3vr964M8EGl"},"source":["do_detected_video(model_ckpt, '/content/data/London_Street.mp4', '/content/data/London_Street_out01.mp4', score_threshold=0.4, do_print=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPJra-WN8IyA"},"source":[""],"execution_count":null,"outputs":[]}]}